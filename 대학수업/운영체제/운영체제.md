# 운영체제 개인 공부 (시험 범위)

작성일시: 2022년 6월 10일 오후 3:41
복습: No

### 스레드(Thread)란?

- 프로세스 내에서 실행되는 프로그램 코드의 흐름을 말한다.
- thread 는 lightweight process라고 불린다.
    - process fork에 비해 thread의 생성시간이 더 빠르기 때문
    - thread 간에 process 자원을 공유할 수 있음
    - thread 간 통신이 용이함.
    - Multiple threads can run simultaneously.

### Threads have their own

- thread id
- cpu context (PC, SP, register, set, etc..)
- Stack
- Priority
- errno

### Threads share

- code and data
- open files (through the PPFDT)
- Current working directory
- User and group IDs
- signal setups and handlers
- PCB

### Thread 와 Prcoess의 비슷한 점

- process와 비슷한 states를 가질 수 있다. (new, ready, running, blocked, terminated)
- Thread는 다른 Thread를 만들 수 있다.

### Thread 와 Process의 다른 점

- Multiple threads 는 같은 address space를 갖지 않아도 동작할 수 있다.
- No “automatic” protection mechanism is in place for threads - they are meant to help each other
    
    ![[single_vs_multi.png]]
    

위 그림을 통해 각 threads는 code, data, files 영역은 공유하지만 각자 registers, stack 영역이 분리되어 있다.

### Thread는 왜 필요한가?

- 여러개의 단위 작업으로 구성된 프로그램에서 요청을 동시에 처리하기 위해서다.
- 예 ) 웹 브라우저
    - 이미지 / 텍스트를 표시하는 thread, 네트워크에서 데이터를 가져오는 thread, 파일 다운로드 받는 thread 등등

### Thread 의 장점

- Responsiveness (응답성)
    - 다른 Thread의 실행 시간이 길거나 입 출력 요청으로 인해 block 되더라도 계속 실행되는 것을 허용한다.
- Resource sharing (자원 공유)
    - 프로세스 내 자원(code, data, files)를 자동적으로 공유한다.
    - OS resources (PCB, PPFDT, etc) 도 공유한다.
- Economy (경제성)
    - 만약 각각의 작업을 위해 별도의 프로세스를 생성한다면, 프로세스 생성 및 문맥 교환(Context Switch)으로 인해 overhead가 발생한다. 이에 비해 multi threading 방식은 훨씬 경제적이다.
    - Take less time to create, schedule, and terminate
    - Solaris 2 : 걍 엄청 빠르다는 것을 보여주는 예시인 것 같다.
    - overhead : 프로그램 실행흐름 도중에 동떨어진 위치의 코드를 실행시켜야 할 때, 추가적인 시간, 메모리, 자원이 사용되는 현상.
- Scalability (확장성)
    - 멀티 프로세서 시스템에서 병렬성이 증가한다.
- Performance
    - Multiple threads can run simultaneously.

### Thread의 단점

- Resource sharing
    - Synchronization needed between threads
- Difficult to write and debug multi-threaded programs

### Multi Threading Model

- User Thread (사용자 스레드)
    - 커널의 지원 / 인식 없이 사용자 공간에서 실행되며 thread library를 통해 제공
        - ex. POSIX Pthreads, Mach C-Threads, Solaris 2 threads
- Kernel Threads (커널 스레드)
    - kernel이 thread를 인식하고 프로세스와 유사하게 스케쥴링 한다.
    - Windows, Linux, macOS 등 대부분의 운영체제가 지원하고 있다.
    - 각 kernel thread는 cpu scheduling을 통해 병렬적으로 실행된다.
        - ex. Windows NT/2000, Solaris 2, Linux
- Many-to-One Model (다대일 모델)
- 
    ![[화면_캡처_2022-06-10_161022.png]]
    
    - 많은 user threads 를 하나의 kernel threads로 mapping한다.
    - 하나의 thread가 blocking system call을 할 경우 전체 프로세스가 block된다.
    - 한 번에 하나의 스레드만 커널에 접근 가능하므로 multi thread가 병렬로 실행될 수 없다.
- One-to-One Model (일대일 모델)
- ![[화면_캡처_2022-06-10_161034.png]]
    
    - 각 user thread를 각각의 kernel thread에 mapping함.
    - 하나의 thread가 blocking system call을 하더라도 다른 thread 작업 가능
    - user thread 개수만큼 kernel thread가 만들어지므로 시스템 성능에 부담을 줄 수 있다.
- Many-to-Many Model(다대다 모델)
    ![[화면_캡처_2022-06-10_161045.png]]
    - 위에 두개를 혼합한 것.
    - 부담도 안주고 병렬 실행 가능함.
- Solaris 2 Threads Model
    - light-weight processes (LWPs), and processes
    - 

### Creating a Thread

```c
int pthread_create (pthread_t *threadp, const pthread_attr_t *attr,
void* (*routine)(void *), arg *arg);

// threadp : the thread we aretrying to create - thread ID (TID)
// attr : used to modify the thread attributes ( stack size, address, etc.)
// routine : The thread function
// arg : any argument we want to pass to the thread function.
// argument는 함수의 변수에 집어넣는 값이다.

//Joining a Thread -> 스레드가 종료될 때 까지 기다리는 함수.
int pthread_join(pthread_t aThread, void **statusp);
// 'statusp' get return value of pthread_exit
// can only join with thread's in the same process address space.
// multiple threads can join with one thread but only one returns successfully;

//Terminating a Thread -> 메인 스레드 종료
void pthread_exit(voie *valuep)
// returns value pointed to by 'valuep' to a joining thread.
```

## CPU Scheduling

### 개념

- 하나의 시스템에서 여러개의 프로세스가 실행되고 있을 때 Running 상태의 프로세스가 CPU를 사용하지 않는 입출력 기능을 요구했다고 가정한다.
    - 사용자에게서 키보드 입력을 요청한다.
    - 파일을 읽거나 쓴다.

프로세스는 해당 입출력이 끝날 때 까지 대기해야 하므로, cpu 사용권을 계속 붙잡고 있어도, 무엇하나 못하는 상태로 볼 수 있겠고 다른 프로세스가 유효하게 사용할 수 있던 CPU 시간을 낭비 한 것과 같아진다. 이를 CPU가 놀고 있다. 라고 볼 수 있다.

따라서 운영체제는 프로세스가 cpu를 사용하지 않는 기능을 실행하면 cpu를 유효하게 사용하지 못하므로, 해당 프로세스의 cpu 이용권을 빼앗아 다른 프로세스에게 줘야 함.

이렇게 cpu가 놀지 않도록 만들지 않는 것을 cpu 스케줄링 이라고 부른다. thread를 지원하지 않는 운영체제에서는 프로세스 스케줄링 지원하는 곳에서는 스레드 스케줄링 이라고 함. 

### 작업유형

프로세스(또는 스레드)에서 요청한 작업은 2가지 유형으로 구분할 수 있다.

- CPU가 필요한 작업 ( = 계산 중심의 작업)
- CPU가 없어도 되는 작업 ( = 입출력 중심의 작업)
    - 어떤 장치와 대화가 필요하다면 CPU가 그 장치의 서비스 루틴을 실행하도록 인터럽트를 발생시킨다. 서비스 루틴 또한 명령어의 집합이므로, CPU 독점적인 작업이다. 이는 CPU가 해당 디바이스와 입출력하는 동안에는 다른 일을 못한다는 것.
    - 시스템 설계사들은 이에 대한 해결책으로 CPU 대신 서비스 루틴을 실행해줄 처리기를 삽입하는데, 이러한 처리기가 있다면 CPU가 없어도 되는 작업이며, 십중팔구 CPU가 아닌 디바이스에 대한 통신 연산이다. 예를 들어 메인보드에 USB 장치를 위한 전용 처리기가 달려있기 때문에, USB장치와 대화가 필요하더라도 CPU가 아닌 전용 처리기가 해당 인터럽트를 처리함, 덕분에 USB / 마우스 / 키보드와 통신을 하여도 CPU는 멈추지 않는다.

### 버스트 사이클

- 즉 작업은 CPU작업 또는 I/O작업 중 하나에 속함. 연속적인 CPU작업이 뭉친 구간을 CPU Burst, 연속적인 I/O작업이 뭉쳐진 구간을 I/O Burst라고 부름. 이 구간들이 번갈아 가며 나타나고, 이를 Burst Cycle이라고 부른다.

## 스케줄링 알고리즘 개념

### 선점, 비선점

CPU 사용권을 어떻게 반납할 지에 따라 선점(preemptive), 비선점(non-preemptive)로 나뉜다.

- 선점 : 작업이 끝나지 않아도 운영체제에 의해 사용권이 회수 될 수 있음.
- 비선점 : 작업이 끝나야만 사용권이 회수될 수 있음. ( = 중간에 회수될 수 없음.)

### 스케줄링 기준

상황에 따라 적합한 스케줄링 알고리즘이 각각 다르다. 하지만 스케줄링 알고리즘의 특징을 비교할 때 고려해야할 사항은 다음과 같다.

### CPU Utilization

CPU 이용률 이다. 처리해야할 작업의 개수가 많은데 CPU를 최대한 이용해야지 않겠나.

### Throughput

처리량 이다. 시스템에서 단위 시간당 완료된 작업의 개수 이다. 완료된 작업의 개수만 세며 선점에 의해 중간에 ready queue로 돌아간 작업은 완료가 아니다.

### Turn-around Time

총 처리 시간 이다. 어떤 작업이 요청되고 완료되기까지 걸린 시간이다. 예로 4초에 요청된 작업이 10초에 끝났다면 총 처리 시간은 6초이다.

이는 Burst Time 개념과 연관되는데, 쉬지 않고 CPU를 할당했을 때의 예상 처리 시간을 뜻한다. 총 처리 시간이 버스트 시간보다 커질 수 있다.

### Waiting Time

대기 시간 이다. ready queue 에서 기다린 시간의 총합을 뜻한다.

선점형 스케쥴링에서는 선점에 의해 중간에 ready queue로 갈 수 있으므로, 이것도 waiting time에 포함된다.

### Response Time

응답 시간 이다. 요청이 도착된 시간에서 응답이 발생한 시점까지 얼마나 오래 기다렸는지를 뜻하지만, 매우 기준이 모호하다. 응답이 발생한 시점의 정의가 사람마다 다르니까.

### 여러 스케줄링 알고리즘을 비교하고 이해하기

# 스케줄링 알고리즘 비교

가장 널리 알려진 스케줄링 알고리즘을 비교하고 각각의 `총처리시간`과 `대기시간`을 측정해보겠습니다.

---

## **First-Come First-Served**

먼저 도착한 순서대로 스케쥴링하는 방법이며, 이름이 너무 길어 흔히 `FCFS`로 불립니다. 구현은 매우 쉽지만, 버스트가 큰 작업이 먼저 들어오면 후행 작업들의 대기시간이 매우 길어지는 단점을 가지고 있습니다. 이것을 `호위효과`(`Convoy Effect`)라고 합니다.

---

![https://blog.kakaocdn.net/dn/wuPX8/btqNVCeuo0g/NF9u5Zh9uYvJQTXRWCeB5K/img.png](https://blog.kakaocdn.net/dn/wuPX8/btqNVCeuo0g/NF9u5Zh9uYvJQTXRWCeB5K/img.png)

위의 작업들을 `FCFS`로 처리하면, 다음과 같은 형태로 처리됩니다.

---

![https://blog.kakaocdn.net/dn/bdrD56/btqNWEiiFTm/mIlhHeNWs0svmzekNi882k/img.png](https://blog.kakaocdn.net/dn/bdrD56/btqNWEiiFTm/mIlhHeNWs0svmzekNi882k/img.png)

총처리시간은 `완료된시각 - 요청된시각`이고, 대기시간은 `큐에서 대기한 시간`이므로 각각을 구하고, 평균을 취하면 `평균 총처리시간`과 `평균 대기시간`을 얻을 수 있습니다.

---

![https://blog.kakaocdn.net/dn/bTy0U9/btqNYxiu6wb/2kDUNDEQhbeKI1hb4KNZeK/img.png](https://blog.kakaocdn.net/dn/bTy0U9/btqNYxiu6wb/2kDUNDEQhbeKI1hb4KNZeK/img.png)

**총처리시간 계산 :**

- `P0` : 0초 도착, 5초 완료이므로 `5(5-0)`초.
- `P1` : 1초 도착, 8초 완료이므로 `7(8-1)`초.
- `P2` : 2초 도착, 16초 완료이므로 `14(16-2)`초.
- `P3` : 3초 도착, 22초 완료이므로 `19(22-3)`초.

---

평균 총처리시간은 `(5 + 7 + 14 + 19)/4`로 계산한 `11.25`초.

---

**대기시간 계산**

- `P0 (Total 0초 대기)`
    - 첫 번째 대기 : 0초부터 0초까지 `0(0-0)`초 대기.
- `P1 (Total 4초 대기)`
    - 첫 번째 대기 : 1초부터 5초까지 `4(5-1)`초 대기.
- `P2 (Total 6초 대기)`
    - 첫 번째 대기 : 2초부터 8초까지 `6(8-2)`초 대기.
- `P3 (Total 13초 대기)`
    - 첫 번째 대기 : 3초부터 16초까지 `13(16-3)`초 대기.

---

평균 대기시간은 `(0 + 4 + 6 + 13)/4`로 계산한 `5.75`초.

---

## **Shortest Job First**

직역하면 `최단 작업 우선, SJF 알고리즘` 입니다. `남은 시간이 가장 짧은 작업`을 선택합니다. 검사 시점에 따라 `선점형`, `비선점형`으로 나뉩니다.

---

### 비선점형

선점을 사용할 수 없으므로 `작업이 끝난 시점`에서 검사합니다.

---

![https://blog.kakaocdn.net/dn/dRBpcc/btqN00Ld9FI/giQhgMzYPvKLpBZXKlKF31/img.png](https://blog.kakaocdn.net/dn/dRBpcc/btqN00Ld9FI/giQhgMzYPvKLpBZXKlKF31/img.png)

`P0가 끝난 시점`에서 `P1, P2, P3` 모두 요청이 도착한 상태이므로 `셋 중에서 가장 Burst Time이 짧은 P1를 선택`합니다. 만약 `P1의 Arrival Time이 5보다 컸다면` P0이 끝난 시점에서 P1은 요청되지 않았으므로 고려되지 않았을 것 입니다.

---

시간이 흘러 P1이 끝난 시점에서, P2가 먼저 요청되었지만 P3의 버스트 시간이 더 짧기 때문에 스케쥴러는 P3을 선택합니다.

---

![https://blog.kakaocdn.net/dn/cx3JT4/btqNWgown6E/fV8nTFoOak21lnGWjleWzK/img.png](https://blog.kakaocdn.net/dn/cx3JT4/btqNWgown6E/fV8nTFoOak21lnGWjleWzK/img.png)

위의 타임라인을 보면 총처리시간과 대기시간을 쉽게 구할 수 있겠죠. `FCFS`보다 `평균 총처리시간과 평균 대기시간이 줄어든 것`을 확인할 수 있습니다.

---

![https://blog.kakaocdn.net/dn/cOb8kK/btqN005xr33/tJWOd3JSxEmiIFngNJ7xI1/img.png](https://blog.kakaocdn.net/dn/cOb8kK/btqN005xr33/tJWOd3JSxEmiIFngNJ7xI1/img.png)

**총처리시간 계산 :**

- `P0` : 0초 도착, 5초 완료이므로 `5(5-0)`초.
- `P1` : 1초 도착, 8초 완료이므로 `7(8-1)`초.
- `P2` : 2초 도착, 22초 완료이므로 `20(22-2)`초.
- `P3` : 3초 도착, 14초 완료이므로 `11(14-3)`초.

---

평균 대기시간은 `(5 + 7 + 20 + 11)/4`로 계산한 `10.75`초.

---

**대기시간 계산**

- `P0 (Total 0초 대기)`
    - 첫 번째 대기 : 0초부터 0초까지 `0(0-0)`초 대기.
- `P1 (Total 4초 대기)`
    - 첫 번째 대기 : 1초부터 5초까지 `4(5-1)`초 대기.
- `P2 (Total 12초 대기)`
    - 첫 번째 대기 : 2초부터 14초까지 `12(14-2)`초 대기.
- `P3 (Total 5초 대기)`
    - 첫 번째 대기 : 3초부터 8초까지 `5(8-3)`초 대기.

---

평균 대기시간은 `(0 + 4 + 12 + 5)/4`로 계산한 `5.25`초.

---

### 선점형

이번에는 선점을 사용할 수 있으므로 `새로운 작업이 도착한 시점`에서도 검사할 수 있습니다.

---

![https://blog.kakaocdn.net/dn/bs6Ec0/btqNVBNpFwE/sSiOn1KXZjHTafkTdoMbC1/img.png](https://blog.kakaocdn.net/dn/bs6Ec0/btqNVBNpFwE/sSiOn1KXZjHTafkTdoMbC1/img.png)

`P0 도중에 P1이 도착`했습니다. 현재 진행중인 작업을 끝내려면 4초가 더 필요하지만, P1을 끝내려면 3초면 되므로 `더 짧은 P1로 교체`합니다. 이후에 `P1이 처리되고 있는 도중에 P2, P3가 도착`하지만 P1이 더 짧으므로 교체되지 않습니다. P1이 완료되면 남은 시간이 가장 짧은(`4초가 남은`) P0가 선택됩니다.

---

![https://blog.kakaocdn.net/dn/cwLfxS/btqNZNL7GvK/vsugtadCwzY4nxcZWa0zs1/img.png](https://blog.kakaocdn.net/dn/cwLfxS/btqNZNL7GvK/vsugtadCwzY4nxcZWa0zs1/img.png)

`총처리시간`은 지금까지와 마찬가지지만 `대기시간`은 약간 달라집니다. 중간로 선점되어 대기큐로 되돌아갔으므로 `다시 대기한 시간`을 포함해야 하기 때문입니다. 즉 `N 번째 대기시간`이 생겨났습니다.

---

![https://blog.kakaocdn.net/dn/bd7rgo/btqNVAHJtYZ/1fb297nQVdZK37A96sDEg1/img.png](https://blog.kakaocdn.net/dn/bd7rgo/btqNVAHJtYZ/1fb297nQVdZK37A96sDEg1/img.png)

**총처리시간 계산 :**

- `P0` : 0초 도착, 8초 완료이므로 `8(8-0)`초.
- `P1` : 1초 도착, 4초 완료이므로 `3(4-1)`초.
- `P2` : 2초 도착, 22초 완료이므로 `20(22-2)`초.
- `P3` : 3초 도착, 14초 완료이므로 `11(14-3)`초.

---

평균 대기시간은 `(8 + 3 + 20 + 11)/4`로 계산한 `10.5`초.

---

**대기시간 계산**

- `P0 (Total 3초 대기)`
    - 첫 번째 대기 : 0초부터 0초까지 `0(0-0)`초 대기.
    - 두 번째 대기 : 1초부터 4초까지 `3(4-1)`초 대기.
- `P1 (Total 0초 대기)`
    - 첫 번째 대기 : 1초부터 1초까지 `0(1-1)`초 대기.
- `P2 (Total 12초 대기)`
    - 첫 번째 대기 : 2초부터 14초까지 `12(14-2)`초 대기.
- `P3 (Total 5초 대기)`
    - 첫 번째 대기 : 3초부터 8초까지 `5(8-3)`초 대기.

---

평균 대기시간은 `(3 + 0 + 12 + 5)/4`로 계산한 `5`초.

---

### 치명적인 단점

`SJF`은 고질적인 문제를 가지고 있습니다.

---

첫 번째는 `Burst Time이 큰 작업이 뒤로 계속 밀린다`는 것이죠. 짧은 작업들이 계속 요청되면, 버스트가 큰 작업의 순서는 영원히 오지 않을 것입니다. 이것을 `기아현상`(`Starvation`)라고 합니다.

---

두 번째는 `요청된 작업의 Burst Time을 계산할 수 없다`는 것 입니다. 예전에 실행했던 경험이 있는 작업이라면 과거의 기록에서 추정할 순 있지만, 정확하게 계산하는 것은 어렵습니다. 여러분은 처음 맡아본 업무의 소요시간을 정확하게 단언할 수 있나요?

---

## **Priority**

직역하면 `우선순위` 입니다. `미리 약속한 우선순위에 따라 다음에 실행될 작업을 결정`하며 우선순위가 남은 Burst Time이 짧은 것이라고 약속하면, SJF 알고리즘과 같아집니다. 즉, `SJF는 Priority의 특별한 케이스`입니다. 따라서 SJF의 특징을 생각하면 Priority의 특징도 얼추 파악할 수 있습니다.

---

1. `비선점` 또는 `선점`이 가능하다.
    - 비선점의 경우, 현재 작업이 끝나고 다음 작업을 결정
    - 선점의의 경우, 새로운 작업이 요청되었을 때에도 다음 작업을 결정
2. `기아현상`이 발생할 수 있다.

---

기아를 해결하는 한 가지 해결 방안은 `노화, Aging`입니다. 시간이 지남에 따라 우선순위를 점차 늘려주는 것 이죠. 처음에는 우선순위가 매우 낮은 작업도 `시간이 흐름에 따라 우선순위가 높아져` 언젠가는 실행될 것 입니다.

---

해당 알고리즘의 계산방법은 `SJF`와 같으므로 생략하겠습니다.

---

## **Round Robin**

라운드 로빈의 기본 원칙은 `모든 요소를 돌아가면서 순회`하는 것 입니다.

---

![https://blog.kakaocdn.net/dn/bSEuRT/btqNVAHJt2Y/vEpAjX8EOSjMdldFQ2IcFK/img.png](https://blog.kakaocdn.net/dn/bSEuRT/btqNVAHJt2Y/vEpAjX8EOSjMdldFQ2IcFK/img.png)

---

기본적인 동작은 `FCFS`와 같으나 `특정 시간`(`Quantum`)만큼만 실행하고, 퀀텀을 사용했는데도 미처 작업을 완료하지 못했다면 선점되어 대기큐의 마지막으로 돌아가고 `다음 작업을 다시 특정 시간만큼 실행`시킵니다. 이러한 특징으로 인해 `시분할 알고리즘`이라고 불리며 `특정 작업이 CPU를 독점하지 못하게 하는 것`과 같습니다.

---

![https://blog.kakaocdn.net/dn/xK3Yk/btqNWFIhq9W/8DgPXkkimP9iFZpGkzMoF0/img.png](https://blog.kakaocdn.net/dn/xK3Yk/btqNWFIhq9W/8DgPXkkimP9iFZpGkzMoF0/img.png)

여기서는 `Quantum = 3`으로 정의하고 계산해보겠습니다.

---

![https://blog.kakaocdn.net/dn/8xlhq/btqNXdkucmS/hMvI2WDkXL45kCbOSd4e8K/img.png](https://blog.kakaocdn.net/dn/8xlhq/btqNXdkucmS/hMvI2WDkXL45kCbOSd4e8K/img.png)

먼저 `P0`을 주어진 시간만큼만 실행하고, 그 다음으로 먼저 들어온 `P1`을 실행합니다. `P1`은 3초만으로 충분하므로 실행된 뒤에는 대기 큐에서 빠져나갑니다. 이것을 반복하면 다음과 같은 타임라인이 만들어집니다.

---

위의 타임라인을 보면 `총처리시간`과 `대기시간`을 간단하게 구할 수 있습니다. 각각의 작업들이 선점되어 대기큐로 돌아갈 수 있으므로 `N번째 대기시간`이 있다는 것을 염두해야 합니다.

---

![https://blog.kakaocdn.net/dn/SrHb9/btqNZMzE5r9/vcqfP0x3PkVZfjDJ6U82Kk/img.png](https://blog.kakaocdn.net/dn/SrHb9/btqNZMzE5r9/vcqfP0x3PkVZfjDJ6U82Kk/img.png)

**총처리시간 계산 :**

- `P0` : 0초 도착, 14초 완료이므로 `14(14-0)`초.
- `P1` : 1초 도착, 6초 완료이므로 `5(6-1)`초.
- `P2` : 2초 도착, 22초 완료이므로 `20(22-2)`초.
- `P3` : 3초 도착, 20초 완료이므로 `17(20-3)`초.

---

평균 대기시간은 `(14 + 5 + 20 + 17)/4`로 계산한 `14`초.

---

**대기시간 계산**

- `P0 (Total 9초 대기)`
    - 첫 번째 대기 : 0초부터 0초까지 `0(0-0)`초 대기.
    - 두 번째 대기 : 3초부터 12초까지 `9(12-3)`초 대기.
- `P1 (Total 2초 대기)`
    - 첫 번째 대기 : 1초부터 3초까지 `2(3-1)`초 대기.
- `P2 (Total 12초 대기)`
    - 첫 번째 대기 : 2초부터 6초까지 `4(6-2)`초 대기.
    - 첫 번째 대기 : 9초부터 14초까지 `5(14-9)`초 대기.
    - 첫 번째 대기 : 17초부터 20초까지 `3(20-17)`초 대기.
- `P3 (Total 11초 대기)`
    - 첫 번째 대기 : 3초부터 9초까지 `6(9-3)`초 대기.
    - 첫 번째 대기 : 12초부터 17초까지 `5(17-12)`초 대기.

---

평균 대기시간은 `(9 + 2 + 12 + 11)/4`로 계산한 `8.5`초.

---

라운드 로빈은 `퀀텀의 크기`에 따라 성능이 좌우됩니다. 퀀텀이 크면 `FCFS`와 같아지므로 성능이 떨어지고, 퀀텀이 작으면 빈번하게 일어나는 `문맥교환`때문에 성능이 떨어집니다.

---

얼핏보면 `SJF`보다 성능이 떨어지는 것 처럼 보이지만, 두 알고리즘의 목표는 서로 다릅니다. `SJF`는 시스템의 처리량을 최대한 높이는 것을 목적으로 하고, `RR`은 모든 작업을 최대한 공평하게 다루는 것을 목적으로 합니다. 따라서 `RR`은 많은 사용자들이 동시에 사용하는 시스템에 적합합니다.

---

## **Multilevel Queue**

이것은 알고리즘이 아닌 `매커니즘`입니다. 작업의 특성마다 효율적인 스케줄링 방식이 다를 수 있음을 인정하기 때문에, 하나의 시스템에서 여러개의 `준비완료 큐`를 사용합니다.

---

당연하지만 각각의 큐는 `서로다른 스케쥴링 알고리즘`을 가질 수 있고, `큐 간의 우선도`도 서로 다를 수 있습니다.

---

![https://blog.kakaocdn.net/dn/bL9cdX/btqNYww5qid/qvWiDVE6YncfKURv47BAG1/img.png](https://blog.kakaocdn.net/dn/bL9cdX/btqNYww5qid/qvWiDVE6YncfKURv47BAG1/img.png)

---

## **Multilevel Feedback Queue**

기존의 `Multilevel Queue`는 작업이 큐 사이를 이동할 수 없었지만 `MFQ는 서로다른 큐 사이의 작업이동을 허용`합니다.

---

`RR`로 구성된 큐를 생각해봅시다. 처음에는 `Q=8`에 삽입하여 짧은 퀀텀을 주다가, 생각보다 작업이 커서 오래 살아남는 것 같다면 `Q=16`로 이동시켜서 퀀텀의 크기를 늘려보고, 이래도 끝나지않으면 아예 `FCFS`로 이동시켜서 더 이상의 선점없이 작업을 끝낼 수 있습니다.

---

이것은 `Priority`를 사용하지 않고 `노화`를 구현한 것 입니다.

---

![https://blog.kakaocdn.net/dn/4QXQQ/btqNVS9dh4z/KRuqeFb0eO3JG1U7M9shhk/img.png](https://blog.kakaocdn.net/dn/4QXQQ/btqNVS9dh4z/KRuqeFb0eO3JG1U7M9shhk/img.png)

## Process Synchronization (프로세스 동기화)

### 프로세스 동기화란?

프로세스는 서로 메세지를 보내고 프로세스 내부에서 쓰레드끼리 자원을 공유하면서 ‘동기화’에 대한 문제가 항상 발생할 수 있다. 즉 공유된 자원에 여러 프로세스, 여러 쓰레드가 동시에 접근하면서 발생하게 된다.

그것을 방지하기 위해 하나의 자원을 한 순간에 하나의 프로세스만이 이용하도록 제어하는 것을 프로세스 동기화라고 한다.

### 동기화가 없다면

데이터 일관성이 깨짐 ⇒ 즉, 한 순간 하나의 데이터의 값이 여러개일수도 있게 됨. 다시 말해 여러개의 스레드가 하나의 변수에 대한 값이 제각각일 수 있게 됨.

→ 데이터의 일관성을 유지하기 위해 프로세스 동기화가 필요하다.

### Critical Section (임계구역)

OS에서 임계구역은 상당히 중요한 부분이다. 멀티 프로세스 환경에서 둘 이상의 프로세스가 동시에 접근해서는 안되는 공유 자원의 코드 영역이다.

### Race condition

- 두 개 이상의 프로세스가 공통 자원을 병행적으로(concurrently) 읽거나 쓰는 동작을 할 때, 공용 데이터에 대한 접근이 어떤 순서에 따라 이루어졌는지에 따라 그 실행 결과가 같지 않고 달라지는 상황을 말한다. 즉, 두 개의 스레드가 하나의 자원을 놓고 서로 사용하려고 경쟁하는 상황을 말한다.

### Ciritical Section 문제를 해결하기 위한 3가지 조건

- Mutual Exclusion (상호배제)
    - 하나의 프로세스가 임계구역에 들어가 있다면, 다른 프로세스는 들어갈 수 없다.
- Progress (진행)
    - 임계구역에 들어간 프로세스가 없다면, 누가 들어갈지 적절히 선택해줘야 한다.
- Bounded Waiting (한정 대기)
    - 기아상태를 방지하기 위해, 한 번 들어갔다 나온 놈은 다음에 들어갈 때 제한을 준다.

기아상태 : 특정 프로세스의 우선순위가 낮아서 원하는 자원을 계속 할당받지 못하는 상태

### Bakery Algorithm

critical section에 들어가기 전에 ticket number를 받는다. 가장 낮은 ticket number를 가진 넘이 critical section에 들어갈 수 있다.

만약 ticket number가 같다면 Pi = Pj 라면 i 와 j값을 비교해서 더 작은넘이 먼저 들어간다.

- Shared data
    - boolean choosing[n];
    - int number[n];
    - 이 두 값의 초기값은 false와 0

```c
do {
	choosing[i] = true; // 번호표를 받는다는 의미
	// 현재 대기중인 number보다 1이 큰 number를 받음
	number[i] = max(number[0], number[1], …, number [n – 1]) + 1;
	choosing[i] = false; //번호를 받은 후 choosing이 false가 됨.
	// for문에서 0 ~ n까지의 번호를 확인한다.
	for (j = 0; j < n; j++) {
		while (choosing[j]); // 어떤 프로세스가 번호표를 받는 중에는 잠시 대기한다는 의미.
		while ( (number[j] != 0) && ((number[j], j) < (number[i], i)) ) ;  //서로 존중?
		//number가 0 = 아직 번호표를 못받음 or 이미 끝난 프로세스, 크기 비교 -> 현재보다 작은
		// 번호라면 우선순위에서 밀리므로 대기.
	}
	critical section
	
	number[i] = 0;   // 만약 내 번호가 n개의 프로세스들의 번호 중에 가장 작다면 임계영역에
										 // 들어간 후 번호를 0으로 바꿈

	remainder section

} while(1);
```

### Synchronization Hardware

- 하드웨어에서 critical section problem을 해결할 수 있는 명령어가 있다.
- Test-And-Set (TSL) Instruction
    - shared data : boolean lock = false;

```c
//Test and modify the content of a word atomically
//tsl 구현부
boolean TestAndSet(boolean &target)
{
	boolean rv = target;
	target = true;
	return rv;
}

//tsl 적용
do {
	while(TestAndSet(lock));
		Critical Section
	lock = false;
		Remainder Section
}
```

- TSL 은 Mutual Exclusion과 Progress는 만족하지만 Bounded Waiting을 만족하지 않아서 좋지 않다고한다.
- Swap Instruction
    - key, lock을 swap하는건데 얘도 Bounded Waiting을 만족하지 못한다.
- A Good Solution (강의 함 들어봐야 할 듯.)

```c
// key는 local로 lock, waiting은 global로 선언
// 모든 변수는 false로 set
do {
	waiting[i] = true;
	key = ture;
	while(waiting[i] && key)
		key = TestAndSet(lock);
//Critical Section
	j = (i + 1) & n;
	while ((j != i) && !waiting[j])
		j = (j + 1) & n;
	if(j == i)
		lock = false;
	else
		waiting[j] = false;
	// Remainder Section
}

```

### Semaphore (세마포어)

공유 자원에 여러 프로세스가 접근하는 것을 막는 것이다.

세마포어는 이를 위해 현재 공유 자원의 상태를 나타내는 카운터 변수를 사용하게 된다.

이 변수는 실제 운영체제 혹은 커널에 값으로 저장되며, 각 프로세는 이를 확인하고 변경할 수 있다. 세마포어는 뮤텍스와 다르게 0혹은 1과같은 이진수 외에 더 큰 숫자를 가지게 할 수 있어 꼭 1개의 프로세스만이 자원을 점유하지 않는다. 카운터 변수의 값이 해당 공유 자원에 접근할 수 있는 임계치가 되며 이를 조정하여 접근할 수 있는 프로세스의 개수를 통제할 수 있다.

- 세마포어는 단순히 공유자원의 개수를 나타내는 변수이다.
- shared data를 보호하기 위해 세마포어를 사용하는데 세마포어 자체가 shared data가 되면 말이 안된다. 두 줄로 구성되지 않고 끼어들 틈이 없게 atomic하게 한번에 수행해야 한다.
- wait, signal 함수
    - shared data가 있다 → 기다리지 않고 사용 s -1 wait() 기다려! 하고 말하는 그런 느낌
    - shared data를 다 사용하고 나온다 s +1 signal() 나 사용 다 함! 하고 말하는 느낌

```c
wait(S) {
	while S <= 0
		no-operation; 0보다 작으면 작동하지 않음.
	S--;
}

signal(S) {
	S++;
}

Shared data : semaphore mutex = 1;
Sturcture of Pi:
do {
	wait(mutex);
		critical section
	signal(mutex);
		remainder section
} while(1);
이것 또한 bounded waiting을 해결하지 못한다.
```

- Atomic Execution
    - Uni-Processor Environment
        - Inhibit interrupts before executing code for wait() and signal() 코드를 실행하기 전 인터럽트 금지.
    - Bus-based Multi-Processor Environment
        - Lock the data bus
        - Use a software solution
- Busy Waiting
    - OS에서는 원하는 자원을 얻기 위해 기다리는 것이 아니라 권한을 얻을 때까지 확인하는 것을 의미한다.
    - CPU의 자원을 쓸데 없이 낭비하기 때문에 좋지 않은 쓰레드 동기화 방식이다.
    - → 해결하기 위해 semaphore를 정의해보자.
- Semaphore Implementation

```c
Define a semaphore as a record
typedef struct {
	int value;
	struct process *L;
} semaphore;
// 프로세스 리스트를 만듦 -> block 시켜서 suspend시킴(waiting영역에 넣음) - 동작을 안함
// busy waiting 문제 해결

// Semaphore operations now defined as
// S.value는 the number of processes waiting for the semaphore를 나타낸다.
void wait(semaphore S){
	S.value--;
	if (S.value < 0) {          //0보다 작을경우 이 프로세스를 wait list에 집어넣고 block시킴
		add this process to S.L;
		block();
	}
}
void signal(semaphore S){
	S.value++;
	if (S.value <= 0) {        //0보다 작거나 같을 경우 wait list에서 제외시키고 wakeup 시킴
		remove process P from S.L;
		wakeup(P);
	}
}
```

- Busy-waiting version이 critical sections이 작을 때 좋고,
- Queue-waiting version이 long critical sections일 때 좋다.
    
    ![[화면_캡처_2022-06-19_200338.png]]
    
- semaphore가 2개인 경우
- P0는 S를 먼저 wait 하고 Q를 그 후에 wait함, P1은 반대로 수행
- 수행을 마친 후 순서대로 SIGNAL을 해줌
- 프로세스 하나가 먼저 수행된 후 다음 프로세스가 수행되면 상관이 없지만 한 줄씩 번갈아가며 수행된다면 문제가 생김
- critical section에 들어가기 전, S와 Q가 0보다 작아지게 되므로 두 프로세스 모두 blocking 됨
- 두 프로세스 모두 blocking 되어 누군가 꺼내주기를 기다리지만 나갈 수 없는 상태가 됨 - deadlock(교착) 상태
- 프로세스가 실행되면서 정해놓은대로 잘 진행되지만 한 프로세스가 계속 blocking 당하는 상황 - starvation상태
- Types of Semaphores
    - Counting semaphore(계수) - 정수값에 제한을 가지지 않음
    - Binary semaphore(이진) - 0또는 1로 한정 → 구현하기 쉬움(세마포어도 구현 가능) 이진은 보통 Mutex를 말한다.
- Bounded-Buffer Problem
    - shared data : semaphore full, empty, mutex; 초기값 0, n, 1;
    
    ```c
    Producer Process
    do {
    	…
    	produce an item in nextp
    	…
    	wait(empty);  // 비어있는지를 확인하는것 -채울 것이 있는 상태인지
    	wait(mutex);  // 사용할 수 있는지를 확인하는 것
    	…
    	add nextp to buffer
    	…
    	signal(mutex); // critical section 사용을 끝냈음을 의미
    	signal(full);  // 다 채웠음을 의미
    } while (1);
    
    Counsumer Process
    do {
    	wait(full)     // 채워져 있는지 확인
    	wait(mutex);   // 사용할 수 있는지 확인
    	…
    	remove an item from buffer to nextc
    	…
    	signal(mutex);  // 다 사용했음을 의미
    	signal(empty);  // 하나를 다 비웠음을 의미
    	…
    	consume the item in nextc
    	…
    } while (1);
    ```
    
    ![[화면_캡처_2022-06-20_100030.png]]

- Readers-Writers Problem
    - text 파일을 편집하는 중에 이 파일을 다른 사용자가 열려고 할 때
    - First Readers and Writers Problems
        - Shared data : semaphore mutex, wrt
        - 초기값 mutex = 1, wrt = 1; readcount = 0;
    
    ```c
    Writer Process
    wait(wrt);
    	…
    	writing is performed
    	…
    signal(wrt);
    
    세마포어의 값을 확인하고 쓸 수 있는 상태면 write 해줌
    그 후 signal -> 끝났음을 알림
    쓸 수 있느냐 없느냐를 확인하는 것
    
    Reader Process
    wait(mutex);
    readcount++;
    if (readcount == 1) // 첫번째 read process인지를 물어본다
    	wait(wrt);
    signal(mutex);
    …
    reading is performed
    …
    wait(mutex);
    readcount--;
    if (readcount == 0)
    signal(wrt);
    signal(mutex);
    ```
    
![[화면_캡처_2022-06-20_100131.png]]
### Dining-Philosophers Problem

- 5명의 철학자들은 평생 정해진 원탁의 자리에서 살아야 함
- 철학자들이 하는 일은 철학하는 것과 음식을 먹는 것 두 가지뿐이라고 모델링
- 접시는 각자 하나씩 총 5개가 있고 젓가락은 접시 양 옆에 한 짝씩 존재하여 이 또한 5개
- 식사를 하는 철학자는 접시 양 옆의 젓가락을 들고 식사를 할 수 있음
- 한 사람씩 식사를 하고 싶다면 순서대로 젓가락을 사용할 수 있지만 동시에 모든 사람이 배가 고파진다면 젓가락이 부족
- 만약 모든 철학자들이 젓가락을 한 짝씩 들고 있다면 모두 식사를 하지 못하게 될 것
- shared data : semaphore chopstick[5]; // initialized to 1

```c
Philosopher i
do {
	wait(chopstick[i])
	wait(chopstick[(i+1)% 5])
	eat
	signal(chopstick[i]);
	signal(chopstick[(i+1)% 5])
	think
} while (1);
```

- 만약 모든 철학자들이 동시에 배고파져서 그들의 왼쪽에 있는 젓가락을 동시에 들면 deadlock이 발생한다.
    - 한번에 4명의 철학자만 동시에 앉을 수 있게 하거나
    - 동시에 양쪽에 있는 젓가락을 들 수 있을 때만 젓가락을 들게하여 해결
    - 홀수의 철학자들은 먼저 왼쪽의 젓가락을 들게 하고 짝수 철학자들은 오른쪽 젓가락을 먼저 들게 하는 방식으로 해결
- 두명의 철학자가 존나 빨리 먹고 존나 빨리 생각하면 젓가락을 계속 쳐 쓰기 때문에 다른 애들이 사용을 못해 starvation이 일어난다.
    
    ![[화면_캡처_2022-06-20_100652.png]]

### Mutex (상호배제)

Mutex는 상호배제 (Mutual Exclusion)를 뜻하는 말로, Critical Section을 가지는 thread들의 running time이 서로 겹치지 않도록 해주는 기법이다. 세마포어와의 가장 큰 차이는 공유 자원에 접근할 수 있는 대상의 개수이다. 뮤텍스는 1개의 thread만이 공유 자원에 접근할 수 있다.

Lock과 Unlock의 개념을 사용한다. 이진 세마포어와 같은 개념이다. 자원을 점유하고 있는 대상이 Lock을 할 수 있는 권한을 가지고 있어 자원을 점유하기 시작할 때 들어가서 Lock을 걸어버림. 이렇게 되면 다른 대상들은 Unlock 상태가 될 때까지 기다렸다 나중에 해당 공유 자원에 접근할 수 있게 됨.

### Monitors

- High-level synchronization construct that allows the safe sharing of an abstract data type among concurrent cooperating processes.
- only one process at at time is active within a monitor.

## Deadlock

### 데드락(Deadlock)이란?

멀티 프로그래밍 환경 또는 멀티 프로세스 환경에서는 여러 프로세스 또는 스레드가 한정된 자원을 동시에 사용하기 위해 항상 경쟁 상태에 놓여있다. 이 때, 어떠한 이유이든 프로세스가 필요한 자원을 획득하지 못하고 영원히 자원을 기다리는 상태로 남아 있는 것을 데드락이라고 한다. 자원을 획득하지 못하고 있다는 점에서 기아상태(starvation state)와 비슷하지만 데드락은 영원히 헤어 나올 수 없다는 점에서 차이가 있다.

### 시스템 모델 설명

Deadlock을 이해하기 위해서는 컴퓨터 시스템에서 자원을 획득하는 과정을 먼저 알아야한다. 여기서 자원이란 CPU, 파일, 메모리, lock 객체 (세마포어, 뮤텍스 등) 컴퓨터 시스템에서 우리가 사용할 수 있는 모든 것들을 총칭하는 추상적인 용어다.

1. 요청(Request) : 자원을 사용하기 위해 요청이 가장 먼저 있어야 한다. 프로세스가 특정 자원을 시스템에게 요청하면 시스템은 현재 이 자원이 사용 가능한지 그렇지 않은지 판단 후, 사용 가능하다면 프로세스에게 할당 한다. 만일 자원이 다른 프로세스에 의해 이미 점유 되어 있는 경우 요청 프로세스는 자원이 사용 가능해 질 때 까지 기다린다 (Wait state)
2. 사용(Use) : 자원에 대한 허가가 떨어지면 프로세스는 자원을 사용할 수 있다.
3. 해제(Release) : 프로세스는 자원의 사용이 끝나면 시스템에게 반환 요청을 한다. 시스템은 자원을 반환 받아 다른 필요한 프로세스가 있다면 해당 프로세스에게 할당한다.

데드락은 특정 셋(set)에 속한 모든 프로세스가 ‘자원이 사용 가능해질 때까지 기다리는 상태 즉 대기 상태(wait state)상태에서 빠져 나오지 못하는 상태를 말한다.

### 데드락(Deadlock)의 조건

프로세스가 데드락에 빠지기 위해선 아래 네 가지 조건이 모두 충족 되어야 한다.

하나라도 충족하지 않는다면 데드락은 발생하지 않는다.

- 상호 배제 (Mutual Exclusion)
    - 프로세스는 최소한 하나의 공유 되지 않는 자원을 가지고 있어야 한다.
- 점유와 대기 (Hold and Wait)
    - 프로세스는 최소한 하나의 자원을 소유하고 있는 상태에서 다른 프로세스에 의해 소유 되어있는 추가 자원을 요청 해야 한다.
- 선점 불가 (No Preemption)
    - 자원을 획득함에 있어 우선권이 없다. 그 어떤 프로세스도 다른 프로세스가 소유하고 있는 자원을 강제로 빼앗아 올 수 없다. 자원을 획득할 수 있는 유일한 방법은 다른 어떤 프로세스도 해당 자원을 점유하고 있지 않을 때 뿐이다.
- 순환 대기 (Circular wait)
    - 프로세스들이 상대방이 필요한 자원을 점유 한 상태로 상대방이 가지고 있는 자원을 요청하는 상태다
    - 예를 들어 프로세스 P1, P2, P3..이 있다면 P1은 P2가 가지고 있는 자원이 해제 되길 기다리고, P2는 P3이 가진 자원, P3은 그 다음, 그 다음..과 같은 형식으로 가장 마지막의 프로세스 Pn가 다시 P1이 가진 자원을 요청하고 해제 되길 기다리는 형태가 아래 그림 처럼 하나의 순환 구조를 이룬다.
        
        ![[다운로드.png]]
    

영어로 기억하는 것이 좋다.

### 자원 할당 그래프(Resource-Allocation Graph)

- 프로세스가 자원을 요청하고 자원이 프로세스에게 할당 되는 ‘방향성’을 가진 그래프로 데드락 발생 여부를 탐지 할 수 있는 그래프다.

![[다운로드 1.png]]
- 여기서 resource들은 모두 mutual exclusion이다.
- p 에서 r로가는 화살표는 요청 화살표, r 에서 p로가는 화살표는 할당 화살표이다.

위 그래프 살펴보면 아래와 같다.

- P1은 R2의 자원을 점유하고 R1의 자원을 대기 중이다. - hold and wait
- p2는 r1과 r2의 자원을 점유하고 r1의 자원을 대기 중 - hold and wait
- p3는 r3의 자원을 가지고 있지만 아무런 추가 지원을 요청하지 않는다.
    - 따라서 순환 대기 상태가 아니므로 위 상황은 데드락 상태가 아니다.
- 위에 그래프에서 p3이 r2의 자원을 요청하는 것을 추가 해보자.
![[화면_캡처_2022-06-19_215454.png]]
    
- p3는 r2의 자원을 요청했으나 r2는 이미 할당할 수 있는 자원을 모두 사용했으므로, p3는 대기 상태에 빠지게 된다, 여기서 r2는 p2에게 할당 되었고, p2는 r3를 기다리고 있다. 하지만 r3는 이미 p3에게 할당 되어 있어 순환 대기 상태에 빠지게 되었다.
    - P3 → R2 → P2 → R3 → P3
    - P3 → R2 → P1 → R1 → P2 → R3 → P3
    - 데드락 발생 !!
        
        ![[화면_캡처_2022-06-19_215748.png]]
        
- P1 → R1 → P2 → R2 → P1으로 얼핏 보면 순환대기 상태가 만들어진다. 하지만 P3에서 작업이 완료 되고 자원을 해제하면 P1에게 할당 될 수 있다. R2 타입의 자원 역시 P4에서 작업이 완료 되고 자원을 해제하면 P2에게 할당 될 수 있으므로 순환 대기 상태가 아니다.

## Deadlock Handling

### Deadlock Prevention

- Mutual Exclusion Prevention
- 상호 배제(mutual exclusion)이라는 것은 공유가 불가능한 자원을 소유하고 있는것을 말한다. 그렇다면 자원을 공유 가능하도록 만들면 데드락은 발생하지 않는다. Read-only 파일이 좋은 예다. 만일 업데이트가 필요 없는 파일이라면 read-only권한으로 자원을 점유 할 수 있다. 파일에 변경이 없으니 여러 프로세스가 동시에 이 파일에 접근 가능하고, 이는 자원을 점유하기 위해 대기하는 프로세스가 없다는 뜻이다. 이로써 상호 배제 조건이 만족하지 않으므로 데드락은 발생 할 수 없다.
하지만 업데이트가 필요한 파일과 같이 어떠한 이유로든 동시에 접근하는 것을 허용하지 못하는 자원의 경우 상호 배제 방지는 적용 할 수 없다.
- Hold and Wait Prevention
- 점유 대기란 프로세스가 자원을 소유한 상태에서 다른 추가 자원을 요청하기 때문에 발생한다. 만일 한 프로세스가 동시에 점유 할 수 있는 자원이 하나로 제한 된다면 다른 자원을 획득하기 위해서는 가지고 있는 자원을 해제 해야만 하기에 점유 대기 방지 상태는 발생하지 않는다.
하지만 여러 자원에 대해 일관성을 보장해야 하는 작업의 경우는 여러 자원을 동시에 접근하여 업데이트 해야만 하므로 이 방법을 적용 할 수 없다.
일관성을 보장하기 위한 방법으로는 마치 여러 자원들을 하나의 묶음 처럼 필요한 자원을 모두 한 번에 할당할 수도 있다. 하지만 이 방법 역시 당장 사용하지 않는 자원을 작업이 끝날때까지 불필요하게 점유하고 있을 수 있는 성능상 단점이 있다.
- Non Preemption Prevention
- 비선점(Non-Preemption)이라는 것은 한번 점유된 자원은 반환 하기 전까지 다른 프로세스에 의해 점유 될 수 없다는 것이다.
첫번째 방법으로는, 어떤 자원을 이미 점유하고 있는 프로세스가 당장 할당 받을 수 없는 다른 추가 자원을 요청한다면 요청 프로세스가 가지고 있는 모든 자원들을 선점형으로 바꾸어 버리는 방법이 있다. 달리 말하면 요청 대기 상태에 빠지는 프로세스의 모든 자원을 암묵적으로 해제(Release)해버리는 것이다. 해제된 리소스들은 요청 대기 자원 리스트에 들어가고, 프로세스는 새로 요청한 자원과 이전에 가지고 있던 자원 모두를 획득 했을 때만 대기 상태에서 벗어나 작업을 다시 시작 할 수 있다.
다른 방법으로는, 프로세스가 자원을 요청하면
    - 대상 자원이 현재 아무런 프로세스에게 할당 되어있지 않은지 확인 한다. 어떤 프로세스도 해당 자원을 점유하고 있지 않다면 요청 프로세스에게 자원을 할당 한다.
    - 만일 대상 자원이 이미 다른 프로세스에게 할당 되어 있고, 그 다른 프로세스가 추가 자원을 대기 중이라면, 다른 프로세스로 부터 해당 자원을 빼앗아 요청 프로세스에게 할당 한다.
    - 만일 대상 자원이 이미 다른 프로세스에 의해 사용 중이라면 요청 프로세스는 대기 상태로 빠진다.
    - 이 상태에서 만일 다른 프로세스가 요청 프로세스가 가지고 있는 자원을 요구하면 그 자원을 해제하여 선점 가능하도록 변경한다.
    - 요청 프로세스는 필요한 모든 자원이 할당 될때까지 대기 상태에 있는다.
- Circular Wait Prevention
- 순환 대기 상태는
- 순환 대기 상태는 내가 필요한 자원을 다른 프로세스에서 선점하고 있고, 그 다른 프로세스가 필요한 자원을 내가 선점하고 있을 때 발생한다. 이를 방지하는 첫번째 방법은, 모든 프로세스가 획득 하는 자원의 순서를 동일하게 맞추는 것이다. 모든 자원마다 고유의 번호를 부여하고 필요한 자원을 번호가 작은 것 부터 큰 순서대로 획득하도록 한다면 추가로 필요한 자원들이 어떠한 프로세스에게도 점유 되어 있지 않음을 보장한다.

## Deadlock Avoidance

앞서 살펴본 데드락 방지(Deadlock Prevent)는 당장 사용하지 않는 자원을 점유하거나, 이미 할당 되었던 자원을 반납해야 하는 등의 전체 성능을 낮추어야 하는 단점이 있.

### 안전 상태(Safe State)

‘안전 상태’라는 것은 시스템이 각 프로세스들에게 데드락을 피할 수 있는 안전한 순서(safe sequence)로 자원을 배분할 수 있는 상태를 의미한다.

### RAG Algorithm

자원 타입 당 사용할 수 있는 인스턴스가 하나일 경우 사용할 수 있는 알고리즘이다. 자원 할당 그래프에서 ‘클레임 화살표’의 개념이 더 추가된다. ‘클레임 화살표’는 프로세스가 미래 언젠가 자원을 요청 할 수도 있다는 것을 나타낸다.

![[화면_캡처_2022-06-20_080336.png]]
시스템은 위와 같은 그래프를 유지하며, 프로세스로부터 자원에 대한 요청을 받으면 순환 대기 상태가 발생하지 않는 경우에만 자원을 할당한다.

### 은행원 알고리즘 (Banker’s Algorithm)

Banker’s Algorithm은 자원 타입 하나당 여러개의 자원 인스턴스가 있어도 적용 가능.

하지만 아래와 같은 단점이 있다.

- 할당 할 수 있는 자원의 수가 일정해야 함
- 시스템의 프로세스 개수가 일정해야 함
- 불안전 상태 방지를 위해 자원 이용도가 낮음

Data Stuctures for the Banker’s Algorithm

- n = number of processes
- m = number of resource type
- Available(가용자원) : Available[m]으로 정의되는 1차원 배열, 각 자원 타입 마다 현재 사용가능한 개수를 저장한다. 만일 Available[j] = k 라면, 자원 타입 Rj의 현재 사용 가능한 인스턴스가 k라는 의미다.
- Max(최대 요구 가능 자원) : Max[n, m]로 정의 되는 2차원 배열. 각 프로세스가 요구할 수 있는 최대 자원 갯수를 나타낸다. 만일 Max[i, j] = k라면, 프로세스 Pi는 Rj 타입의 자원을 최대 k개 까지 요구할 수 있다는 의미이다.
- Allocation(현재 할당 자원) : Allocation[n, m]로 정의되는 2차원 배열. 각 프로세스 별 현재 할당 되어 있는 자원 갯수를 나타낸다. 만일 Allocation[i, j] = k 라면, 프로세스 Pi에게 Rj타입의 자원이 k개 할당 되어 있다는 의미다.
- Need(필요 자원) : Need[n, m]로 정의 되는 2차원 배열. 각 프로세스 별 작업을 완료하기 위해 추가로 필요한 자원 개수를 의미한다. 만일 Need[i, j] = k 라면, 프로세스 Pi가 작업을 완료하기 위해서는 Rj타입의 자원이 k개 더 필요하다는 의미.
- 안전상태 판단 알고리즘(Safety Algorithm)
- 배열 인덱스 i는 1부터 2, 3, … n까지 순차 증가하는 for문의 인덱스라고 정의한다.
1. Work[m], Finish[n]. 이렇게 두개의 1차원 배열이 있다.알고리즘이 시작 되면 Work := Available로, Finish[i] := false 로 초기화 된다
2. 각 프로세스가 아래의 두 조건에 해당하는지 검사한다.
    
    Finish[i] = false
    Needi <= Work
    
3. 조건에 부합한다면 3번으로, 만일 조건에 부합하는 i가 하나도 없다면 4번으로
Work := Work + AllocationiFinish[i] := true2번 과정으로 이동
4. 만일 모든 Finish[i]가 true면 현재 상태는 안전한 상태다.

위 알고리즘은 안전 상태를 결정하기 위해 m x n2 만큼의 오퍼레이션이 필요 할 수 있다.

- Resource-Request Algorithm for Pi
1. 만일 요청 자원이 필요 자원이 보다 작거나 같다면(Requesti <= Needi) 2번 과정으로 이동. 그렇지 않다면 프로세스 최대 필요 자원양 보다 많이 요청한 것이므로 에러를 발생 시킨다.
2. 만일 요청 자원이 가용 자원이 보다 작거나 같다면(Requesti <= Available) 3번 과정으로 이동. 그렇지 않다면 현재 가용 자원이 부족한 상태이므로 Pi는 대기한다.
3. 아래와 같이 '자원 할당 상태'를 수정하여 시스템이 요청된 리소르를 할당한 척 하도록 한다.

Available := Available - Requesti

Allocationi := Allocationi + Requesti
Needi := Needi - Requesti

할당한 척이라 표현한 이유는 자원을 할당한 상태가 아니고, 이렇게 자원을 할당해도 안전 상태가 유지되는지를 확인하기 위해 ‘자원 할당 상태’ 업데이트만 했기 때문.

if safe ⇒ the resources are allocated to Pi

If unsafe ⇒ Pi must wait, and the old resource-allocation state is restored.(이전 상태로 돌아간다는 뜻)